{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sample points:  41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index from  0  to  19\n",
      "041\n",
      "141\n",
      "241\n",
      "Index from  20  to  39\n",
      "041\n",
      "141\n",
      "241\n",
      "Index from  40  to  59\n",
      "041\n",
      "141\n",
      "241\n",
      "Index from  60  to  79\n",
      "041\n",
      "141\n",
      "241\n",
      "Index from  80  to  96\n",
      "041\n",
      "141\n",
      "241\n"
     ]
    }
   ],
   "source": [
    "# %load noise_reduction.py\n",
    "\n",
    "# Noise reduction\n",
    "# using NN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# 問題設定\n",
    "noise_mu = 15\n",
    "noise_sigma = 10\n",
    "size1 = 20\n",
    "numberOfPoints = 2 * size1 + 1\n",
    "numberOfData = 100\n",
    "numberOfTest = 3\n",
    "numberOfTrain = numberOfData - numberOfTest\n",
    "miniBatchSize = 20\n",
    "\n",
    "# アルゴリズム設定\n",
    "# Number of perceptrons at 2nd layer\n",
    "# default: 10000\n",
    "numberOf2ndPerceptrons = 10000\n",
    "#\n",
    "stddevOfPerceptrons = 0.03  # 0.1 #0.03\n",
    "learningRate = 0.9  # 0.1 #0.9\n",
    "\n",
    "\n",
    "def Gaussian(x, mu, sigma):\n",
    "    return math.exp(-0.5 * (x - mu) ** 2 / sigma ** 2)\n",
    "\n",
    "\n",
    "samplePoints = range(-size1, size1 + 1)\n",
    "signal = np.zeros((numberOfData, numberOfPoints))\n",
    "print(\"# of sample points: \", len(samplePoints))\n",
    "obs = np.zeros((numberOfData, numberOfPoints))\n",
    "\n",
    "dSigs = np.random.rand(numberOfData).astype(\"float32\")\n",
    "\n",
    "for j in range(numberOfData):\n",
    "    for i in range(numberOfPoints):\n",
    "        signal[j][i] = Gaussian(samplePoints[i], 0, 0.5 + 0.05 * size1 * dSigs[j])\n",
    "        obs[j][i] = signal[j][i] + 0.2 * Gaussian(\n",
    "            samplePoints[i], noise_mu, noise_sigma)\n",
    "        # print(str(i) + \" \" + str(samplePoints[i]) + \" \" + str(obs[i]))\n",
    "\n",
    "# Visualize for check\n",
    "for j in range(min(3, numberOfData)):\n",
    "    plt.scatter(samplePoints, signal[j])\n",
    "    plt.scatter(samplePoints, obs[j])\n",
    "    plt.show()\n",
    "\n",
    "# 入力データを定義\n",
    "x = tf.placeholder(tf.float32, [None, numberOfPoints], name=\"x_input\")\n",
    "\n",
    "# 入力画像をログに出力\n",
    "img = tf.reshape(x, [-1, numberOfPoints, 1, 1])\n",
    "tf.summary.image(\"log_input_data\", img, 2)\n",
    "\n",
    "# 入力層から中間層\n",
    "with tf.name_scope(\"second_layer\"):\n",
    "    w_1 = tf.Variable(tf.truncated_normal(\n",
    "        [numberOfPoints, numberOf2ndPerceptrons], stddev=stddevOfPerceptrons), name=\"w1\")\n",
    "    b_1 = tf.Variable(tf.zeros([numberOf2ndPerceptrons]), name=\"b1\")\n",
    "    h_1 = tf.nn.relu(tf.matmul(x, w_1) + b_1)\n",
    "\n",
    "    # 中間層の重みの分布をログ出力\n",
    "    tf.summary.histogram('log_w_1', w_1)\n",
    "\n",
    "# 中間層から出力層\n",
    "with tf.name_scope(\"output_layer\"):\n",
    "    w_2 = tf.Variable(tf.truncated_normal(\n",
    "        [numberOf2ndPerceptrons, numberOfPoints], stddev=stddevOfPerceptrons), name=\"w2\")\n",
    "    b_2 = tf.Variable(tf.zeros([numberOfPoints]), name=\"b2\")\n",
    "    # out = tf.nn.softmax(tf.matmul(h_1, w_2) + b_2)\n",
    "    out = tf.matmul(h_1, w_2) + b_2\n",
    "\n",
    "# 誤差関数\n",
    "y = tf.placeholder(tf.float32, [None, numberOfPoints], name=\"y_input\")\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.square(y - out))\n",
    "\n",
    "    # 誤差をログ出力\n",
    "    tf.summary.scalar(\"log_loss\", loss)\n",
    "\n",
    "# 訓練\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.GradientDescentOptimizer(learningRate).minimize(loss)\n",
    "\n",
    "# 評価\n",
    "# correct = tf.equal(tf.argmax(out,1), tf.argmax(y,1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "# 初期化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(\"logs\", sess.graph)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "#         sess.run(train_step, feed_dict={x:obs[j] ,y:signal[j]})\n",
    "    for j in range(0, numberOfTrain, miniBatchSize):\n",
    "        idxEnd = min(j + miniBatchSize, numberOfTrain)\n",
    "        print(\"Index from \", j, \" to \", idxEnd - 1)\n",
    "\n",
    "        sess.run(\n",
    "            train_step, feed_dict={x:obs[j:idxEnd], y:signal[j:idxEnd]})\n",
    "\n",
    "        test_data = obs[numberOfTrain:numberOfData]\n",
    "\n",
    "    # tf.reshapeの第1引数に、numpy.arrayを入れていいのかあやしい。\n",
    "        test_images = np.reshape(test_data, [\n",
    "            numberOfData - numberOfTrain, numberOfPoints])  # , 1, 1])\n",
    "        test_labels = signal[numberOfTrain:numberOfData]\n",
    "\n",
    "    # test_dataからノイズ除去\n",
    "        outVal = sess.run(out, feed_dict={x:test_data})\n",
    "\n",
    "    #         if step % 10 == 0:\n",
    "    #             acc_val = sess.run(accuracy ,feed_dict={x:test_images, y:test_labels})\n",
    "    #             print('Step %d: accuracy = %.2f' % (step, acc_val))\n",
    "\n",
    "        if j % 1 == 0:\n",
    "            for i in range(len(outVal)):\n",
    "                print(str(i) + str(len(outVal[i])))\n",
    "                plt.scatter(samplePoints, outVal[i], s=numberOfPoints)\n",
    "                plt.scatter(samplePoints, signal[numberOfTrain + i])\n",
    "                # plt.show()\n",
    "\n",
    "            # ログを取る処理を実行する（出力はログ情報が書かれたプロトコルバッファ）\n",
    "            # test_labelsを2次元arrayで与えていいか不明。\n",
    "            summary_str = sess.run(summary_op, feed_dict={x:test_images, y:test_labels})\n",
    "            # ログ情報のプロトコルバッファを書き込む\n",
    "            summary_writer.add_summary(summary_str, idxEnd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
